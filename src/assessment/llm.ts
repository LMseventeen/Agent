import OpenAI from "openai";
import { LearningItem } from "../types.js";

export async function llmBasedAssessment(
  answer: string,
  item: LearningItem
): Promise<{ cognitiveState: string; reasoning: string }> {
  const modelName = "deepseek-ai/DeepSeek-V3.2";
  // æ¸…ç† baseURLï¼ˆç§»é™¤å¤šä½™çš„ /chat/completions åç¼€ï¼‰
  let apiBase = process.env.OPENAI_API_BASE || "https://api.siliconflow.cn/v1";
  apiBase = apiBase.replace(/\/chat\/completions\/?$/, "");
  
  console.log(`  ğŸ¤– è¯„ä¼°æ¨¡å‹: ${modelName}`);
  console.log(`  ğŸŒ API Base: ${apiBase}`);
  
  const client = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    baseURL: apiBase,
  });

  const prompt = `ä½ æ˜¯ä¸€ä½æ•™å­¦è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°å­¦ç”Ÿå¯¹ä»¥ä¸‹å­¦ä¹ ç›®æ ‡çš„ç†è§£ç¨‹åº¦ã€‚

å­¦ä¹ ç›®æ ‡ï¼š${item.goal}

å­¦ç”Ÿå›ç­”ï¼š
"${answer}"

è¯·åˆ¤æ–­å­¦ç”Ÿå½“å‰çš„è®¤çŸ¥çŠ¶æ€ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š

1. intuition_but_unclear - æœ‰ç›´è§‰ä½†è¯´ä¸æ¸…ï¼ˆçŸ¥é“å¤§æ¦‚æ–¹å‘ï¼Œä½†è¡¨è¿°æ¨¡ç³Šï¼Œæœªè§¦åŠæ ¸å¿ƒï¼‰
2. can_describe_with_structure - èƒ½ç”¨ç»“æ„åŒ–è¯­è¨€æè¿°ï¼ˆèƒ½è¯´æ¸…æ¥šå…³é”®è¦ç´ ã€å› æœå…³ç³»ã€è¾¹ç•Œï¼‰
3. fully_structured - å®Œå…¨ç»“æ„åŒ–ï¼ˆæœ‰æ¸…æ™°çš„æ¦‚å¿µæ¨¡å‹å’Œå±‚æ¬¡ï¼‰
4. transferable - å¯è¿ç§»åº”ç”¨ï¼ˆèƒ½ç±»æ¯”ã€ä¸¾ä¸€åä¸‰ï¼‰

è¯·ä»¥ JSON æ ¼å¼å›å¤ï¼š
{
  "cognitiveState": "é€‰æ‹©çš„çŠ¶æ€",
  "reasoning": "ç®€çŸ­è¯´æ˜ç†ç”±ï¼ˆä¸€å¥è¯ï¼‰"
}`;

  const response = await client.chat.completions.create({
    model: modelName,
    messages: [{ role: "user", content: prompt }],
    temperature: 0.7,
  });
  
  try {
    let content = response.choices[0]?.message?.content || "";
    // ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
    content = content.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim();
    const result = JSON.parse(content);
    return result;
  } catch (e) {
    console.error("âŒ LLM è¿”å›æ ¼å¼é”™è¯¯:", response.choices[0]?.message?.content);
    return {
      cognitiveState: "intuition_but_unclear",
      reasoning: "è§£æå¤±è´¥ï¼Œé»˜è®¤åˆ¤æ–­",
    };
  }
}

